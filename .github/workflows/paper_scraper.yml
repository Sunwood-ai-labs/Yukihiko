name: 論文スクレイパーの実行

on:
  schedule:
    - cron: '00 11 * * 1-5'  # 月曜日から金曜日の19:30 JST（10:30 UTC）に実行
  workflow_dispatch:  # 手動実行のオプション

# 明示的な権限設定を追加
permissions:
  contents: write

jobs:
  scrape-and-update:
    name: スクレイプと更新
    runs-on: ubuntu-latest
    steps:
      - name: リポジトリのチェックアウト
        uses: actions/checkout@v2

      - name: Pythonのセットアップ
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: 依存パッケージのインストール
        run: |
          python -m pip install --upgrade pip
          pip install feedparser requests beautifulsoup4 loguru art lxml

      - name: 論文スクレイパーの実行
        run: python .github/scripts/scraper.py

      - name: 変更の確認
        id: check_changes
        run: |
          git diff --exit-code || echo "changes=true" >> $GITHUB_OUTPUT

      - name: 変更があれば新しいブランチを作成してコミット
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config --local user.email "yukihiko.fuyuki@gmail.com"
          git config --local user.name "yukihiko-fuyuki"
          git checkout -b update-papers-data
          git add papers.json
          git commit -m "📚 [paper] スクレイピングした論文データを更新"
          git push -u origin update-papers-data

      - name: プルリクエストの作成
        if: steps.check_changes.outputs.changes == 'true'
        uses: peter-evans/create-pull-request@v3
        with:
          token: ${{ secrets.YOUR_PERSONAL_ACCESS_TOKEN_YUKIHIKO }}
          commit-message: 📚 [paper] スクレイピングした論文データを更新
          title: '論文データの更新'
          body: 'このプルリクエストは自動的に作成されました。スクレイピングされた最新の論文データが含まれています。'
          branch: update-papers-data
          base: main

      - name: プルリクエストの自動マージ
        if: steps.check_changes.outputs.changes == 'true'
        uses: pascalgn/automerge-action@v0.14.3
        env:
          GITHUB_TOKEN: ${{ secrets.YOUR_PERSONAL_ACCESS_TOKEN_YUKIHIKO }}
          MERGE_LABELS: ""
          MERGE_METHOD: "squash"
          MERGE_COMMIT_MESSAGE: "🔀 論文データを更新 (自動マージ)"
          MERGE_DELETE_BRANCH: "true"
